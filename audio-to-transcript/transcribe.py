print("ğŸš€ è„šæœ¬æ–‡ä»¶è¢«æˆåŠŸæ‰§è¡Œ")
import os
from openai import OpenAI
from dotenv import load_dotenv

def transcribe_audio(
    input_dir="audio",
    output_path="transcript/transcript.txt"
):
    """
    ä» audio/ æ–‡ä»¶å¤¹è¯»å–éŸ³é¢‘æ–‡ä»¶ï¼Œè°ƒç”¨ OpenAI API è½¬å½•å¹¶å†™å…¥ transcript/transcript.txt
    """
    load_dotenv()
    client = OpenAI()

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    for filename in os.listdir(input_dir):
        if not filename.lower().endswith((".wav", ".mp3", ".m4a")):
            continue

        file_path = os.path.join(input_dir, filename)
        print(f"ğŸ§ æ­£åœ¨è½¬å½•: {filename} ...")

        with open(file_path, "rb") as f:
            result = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=f
            )

        with open(output_path, "a") as out:
            out.write(f"### {filename}\n")
            out.write(result.text + "\n\n")

        print(f"âœ… {filename} è½¬å½•å®Œæˆï¼Œå·²å†™å…¥ {output_path}")

if __name__ == "__main__":
    transcribe_audio()